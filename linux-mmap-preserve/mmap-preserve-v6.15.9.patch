Patchset improving Linux kernel performance while low on memory
mm: preserves portion of mmap pages from being evicted while low on memory
 - Improves performance under heavy memory pressure, reduces stalls
 - Fully configurable via sysctl (vm.mmap_preserve_ratio, default = 10%)

More information can be found here: https://github.com/LekKit/linux-mmap-preserve


diff -Naurp a/include/linux/swap.h b/include/linux/swap.h
--- a/include/linux/swap.h	2025-08-02 15:47:09.452093090 +0300
+++ b/include/linux/swap.h	2025-08-02 15:48:47.023953329 +0300
@@ -425,6 +425,7 @@ extern unsigned long mem_cgroup_shrink_n
 						unsigned long *nr_scanned);
 extern unsigned long shrink_all_memory(unsigned long nr_pages);
 extern int vm_swappiness;
+extern int vm_mmap_preserve_ratio;
 long remove_mapping(struct address_space *mapping, struct folio *folio);
 
 #ifdef CONFIG_NUMA

diff -Naurp a/mm/vmstat.c b/mm/vmstat.c
--- a/mm/vmstat.c	2025-08-02 15:47:09.857770977 +0300
+++ b/mm/vmstat.c	2025-08-02 15:55:08.414694078 +0300
@@ -2224,6 +2224,15 @@ static const struct ctl_table vmstat_tab
 		.proc_handler	= vmstat_refresh,
 	},
 #endif
+	{
+		.procname	= "mmap_preserve_ratio",
+		.data		= &vm_mmap_preserve_ratio,
+		.maxlen		= sizeof(vm_mmap_preserve_ratio),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax,
+		.extra1		= SYSCTL_ZERO,
+		.extra2 	= SYSCTL_ONE_HUNDRED,
+	},
 #ifdef CONFIG_NUMA
 	{
 		.procname	= "numa_stat",

diff -Naurp a/mm/vmscan.c b/mm/vmscan.c
--- a/mm/vmscan.c	2025-08-02 15:47:09.857271332 +0300
+++ b/mm/vmscan.c	2025-08-02 15:48:47.027953279 +0300
@@ -290,6 +290,11 @@ static int sc_swappiness(struct scan_con
 			continue;				\
 		else
 
+/*
+ * Percentage of non-evictable mmaped pages relative to total memory
+ */
+int vm_mmap_preserve_ratio = 10;
+
 static void set_task_reclaim_state(struct task_struct *task,
 				   struct reclaim_state *rs)
 {
@@ -2648,6 +2653,24 @@ out:
 
 		nr[lru] = scan;
 	}
+
+	if (vm_mmap_preserve_ratio && nr[LRU_ACTIVE_FILE]) {
+		unsigned long active_file_pages;
+		unsigned long preserved_pages;
+		unsigned long excess_pages;
+
+		/*
+		 * Prevent scanning up to N% of file-backed pages in memory.
+		 * E.q. with vm_mmap_preserve_ratio = 10 on 10G system this means
+		 * at most 1G non-evictable mmaped pages
+		 */
+		active_file_pages = global_node_page_state(NR_ACTIVE_FILE);
+		preserved_pages = totalram_pages() / 100 * vm_mmap_preserve_ratio;
+		excess_pages = (active_file_pages > preserved_pages)
+			? (active_file_pages - preserved_pages) : 0;
+
+		nr[LRU_ACTIVE_FILE] = min(excess_pages, nr[LRU_ACTIVE_FILE]);
+	}
 }
 
 /*
